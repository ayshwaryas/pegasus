{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sccloud as scc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bokeh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Matrix File\n",
    "\n",
    "For this tutorial, we provide a count matrix dataset on Human Bone Marrow with 8 donors. It is stored in scCloud hdf5 format (with file extension \".h5sc\").\n",
    "\n",
    "Terra Notebook uses Google Cloud SDK command to retrieve the data from a remote Google Bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_file = \"MantonBM_nonmix_subset.h5sc\"\n",
    "gf_src = \"gs://fc-a40546ad-5019-43b9-b4de-5951d1e65948/\" + src_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp $gf_src ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the downloading is finished, you can load the file using scCloudPy `read_input` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = scc.read_input(src_file)\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count matrix is manipulated as an Annotated Data Matrix structure (see [anndata.AnnData](https://anndata.readthedocs.io/en/latest/anndata.AnnData.html) for details; the figure below is also borrowed from this link):\n",
    "\n",
    "<img src=\"https://falexwolf.de/img/scanpy/anndata.svg\" width=\"40%\" />\n",
    "\n",
    "It has 5 major parts:\n",
    "* Raw count matrix: `adata.X`, a [Scipy sparse matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html), with rows the cell barcodes, columns the genes/features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains $48,000$ barcodes and $33,694$ genes.\n",
    "\n",
    "* Cell barcode attributes: `adata.obs`, a [Pandas data frame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) with barcode as the index. For now, there is only one attribute `\"Channel\"` referring to the donor from which the cell comes from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['Channel'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the summary above, you can see that each of the 8 donors (numbered from 1 to 8) gives $6,000$ cells.\n",
    "\n",
    "* Gene attributes: `adata.var`, also a Pandas data frame, with gene name as the index. For now, it only has one attribute `\"gene_ids\"` referring to the unique gene ID in the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Unstructured information: `adata.uns`, a Python [hashed dictionary](https://docs.python.org/3/library/collections.html#collections.OrderedDict). It usually stores information not restricted to barcodes or features, but about the whole dataset, such as its genome reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['genome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Finally, embedding attributes on cell barcodes: `adata.obsm`; as well as on genes, `adata.varm`. We'll see it in later sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Filtration\n",
    "\n",
    "The first step in preprocessing is to perform the quality control analysis, and remove cells and genes of low quality.\n",
    "\n",
    "We can generate QC metrics using the following method with default settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.qc_metrics(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics considered are:\n",
    "* Number of genes: by default, keep cells with $500 \\leq \\text{# Genes} < 6000$;\n",
    "* Number of UMIs: by default, keep cells with $100 \\leq \\text{# UMIs} < 600,000$;\n",
    "* Percent of Mitochondrial genes: by default, keep cells with percent $< 10\\%$;\n",
    "* Percent of cells: by default, genes that are expressed in at least $0.05\\%$ of cells are marked as `robust`.\n",
    "\n",
    "For details on customizing your own thresholds, see [documentation](https://sccloudpy.readthedocs.io/en/latest/api/sccloud.qc_metrics.html).\n",
    "\n",
    "Numeric summaries on filtration on cell barcodes and genes can be achieved by `get_filter_stats` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_samples, stats_genes = scc.get_filter_stats(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are two pandas data frames, one for samples, the other for genes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Filtration stats w.r.t. samples:\")\n",
    "stats_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Filtration stats w.r.t. genes:\")\n",
    "stats_genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also check the QC stats via plots. First is the violin plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.violin(adata, keys = ['n_genes', 'n_counts', 'percent_mito'], by = 'passed_qc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cells marked with `passed_qc == True` are those passing QC, while the others will be filtered out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then is scatterplot on the QC metrics on samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.scatter(adata, 'n_genes', 'n_counts', color = 'passed_qc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot indicates that number of UMIs and number of genes are positively correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.scatter(adata, 'n_genes', 'percent_mito', color = 'passed_qc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above indicates that cells with high percent of mitochondrial genes tend to have fewer signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now filter data based on QC metrics set in `qc_metrics`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.filter_data(adata)\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After filtration, $34,654$ cells ($72.20\\%$) and $23,460$ genes ($69.63\\%$) are kept.\n",
    "\n",
    "We can also view the cells after filtration w.r.t. donors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['Channel'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization and Logarithmic Transformation\n",
    "\n",
    "After filtration, we need to first normalize the distribution of cells w.r.t. each gene to have the same count (default is $10^5$, see [documentation](https://sccloudpy.readthedocs.io/en/latest/api/sccloud.log_norm.html)), and then transform into logarithmic space by $log(x + 1)$ to avoid number explosion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.log_norm(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the downstream analysis, we may need to make a copy of the count matrix, in case of coming back to this step and redo the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_trial = adata.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highly Variable Gene Selection\n",
    "\n",
    "**Highly Variable Genes (HVG)** are more likely to convey information discriminating different cell types and states.\n",
    "Thus, rather than considering all genes, people usually focus on selected HVGs for downstream analyses.\n",
    "\n",
    "You need to set `consider_batch` flag to consider or not consider batch effect. At this step, set it to `False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.highly_variable_features(adata_trial, consider_batch = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, we select 2000 HVGs using the scCloud selection method. Alternative, you can also choose the traditional method that both *Seurat* and *SCANPY* use, by setting `flavor == 'Seurat'`. See [documentation](https://sccloudpy.readthedocs.io/en/latest/api/sccloud.highly_variable_features.html) for details.\n",
    "\n",
    "Below is a scatterplot of highly variable genes for this dataset. Each point stands for one gene. Orange points are selected to be highly variable genes, which account for the majority of variation of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.variable_feature_plot(adata_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below lists the top 5 HVGs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_trial.var.loc[adata_trial.var['highly_variable_features']].sort_values(by = 'hvf_rank').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis\n",
    "\n",
    "To reduce the dimension of data, Principal Component Analysis (PCA) is widely used. Briefly speaking, PCA transforms the data from original dimensions into a new set of Principal Components (PC) of a much smaller size. In the transformed data, dimension is reduced, while PCs still cover a majority of the variation of data. Moreover, the new dimensions (i.e. PCs) are independent with each other.\n",
    "\n",
    "`scCloudPy` uses the following method to perform PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.pca(adata_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `scc.pca` uses:\n",
    "* Before PCA, scale the data to standard Normal distribution $N(0, 1)$, and truncate them with max value $10$;\n",
    "* Number of PCs to compute: 50;\n",
    "* Apply PCA only to highly variable features.\n",
    "\n",
    "See [its documentation](https://sccloudpy.readthedocs.io/en/latest/api/sccloud.pca.html) for customization.\n",
    "\n",
    "To explain the meaning of PCs, let's look at the first PC (denoted as $PC_1$), which covers the most of variation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_pc1 = adata_trial.uns['PCs'][:, 0]\n",
    "coord_pc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an array of 2000 elements, each of which is a coefficient corresponding to one HVG.\n",
    "\n",
    "With the HVGs as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_trial.var.loc[adata_trial.var['highly_variable_features']].index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$PC_1$ is computed by\n",
    "\n",
    "\\begin{equation*}\n",
    "PC_1 = \\text{coord_pc1}[0] \\cdot \\text{HES4} + \\text{coord_pc1}[1] \\cdot \\text{ISG15} + \\text{coord_pc1}[2] \\cdot \\text{TNFRSF18} + \\cdots + \\text{coord_pc1}[1997] \\cdot \\text{S100B} + \\text{coord_pc1}[1998] \\cdot \\text{MT-CO1} + \\text{coord_pc1}[1999] \\cdot \\text{MT-CO3}\n",
    "\\end{equation*}\n",
    "\n",
    "Therefore, all the 50 PCs are the linear combinations of the 2000 HVGs.\n",
    "\n",
    "The calculated PCA count matrix is stored in the `obsm` field, which is the first embedding object we have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_trial.obsm['X_pca'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the $34,654$ cells, its count is now w.r.t. 50 PCs, instead of 2000 HVGs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbors\n",
    "\n",
    "All the downstream analysis, including clustering and visualization, needs to construct a k-Nearest-Neighbor (kNN) graph on cells. We can build such a graph using `neighbors` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.neighbors(adata_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It uses the default setting:\n",
    "* For each cell, calculate its 100 nearest neighbors;\n",
    "* Use PCA matrix for calculation;\n",
    "* Use L2 distance as the metric;\n",
    "* Use [hnswlib](https://github.com/nmslib/hnswlib) search algorithm to calculate the approximated nearest neighbors in a really short time.\n",
    "\n",
    "See [its documentation](https://sccloudpy.readthedocs.io/en/latest/api/sccloud.neighbors.html) for customization.\n",
    "\n",
    "Below is the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Get {} nearest neighbors (excluding itself) for each cell.\".format(adata_trial.uns['pca_knn_indices'].shape[1]))\n",
    "adata_trial.uns['pca_knn_indices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_trial.uns['pca_knn_distances']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row corresponds to one cell, listing its neighbors (not including itself) from nearest to farthest. `adata_trial.uns['pca_knn_indices']` stores their indices, and `adata_trial.uns['pca_knn_distances']` stores distances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering and Visualization\n",
    "\n",
    "Now we are ready to cluster the data for cell type detection. `scCloudPy` provides 4 clustering algorithms to use. In this tutorial, we use the Louvain algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.louvain(adata_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, Louvain algorithm finds 19 clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_trial.obs['louvain_labels'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check each cluster's composition regarding donors via a composition plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.composition_plot(adata_trial, by = 'louvain_labels', condition = 'Channel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can see a clear batch effect in the plot: e.g. Cluster 10 and 13 have most cells from Donor 3.\n",
    "\n",
    "We can see it more clearly in its FIt-SNE plot (a visualization algorithm which we will talk about later):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.fitsne(adata_trial)\n",
    "scc.embedding(adata_trial, basis = 'fitsne', keys = ['louvain_labels', 'Channel'],\n",
    "              size=1, alpha=0.8, color=bokeh.palettes.all_palettes['Category20'][20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Correction\n",
    "\n",
    "Batch effect occurs when data samples are generated in different conditions, such as date, weather, lab setting, equipment, etc. Unless informed that all the samples were generated under the similar condition, people may suspect presumable batch effects if they see a visualization graph with samples kind-of isolated from each other.\n",
    "\n",
    "For this dataset, we need the batch correction step to reduce such a batch effect, which is observed in the plot above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.highly_variable_features(adata, consider_batch = True)\n",
    "scc.correct_batch(adata, features = 'highly_variable_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['fmat_highly_variable_features'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch correction result is stored at `adata.uns['fmt_highly_variable_features']`. By default, it uses `adata.obs['Channel']` as the batch key, i.e. there are 8 batches in this dataset.\n",
    "\n",
    "See [its documnetation](https://sccloudpy.readthedocs.io/en/latest/api/sccloud.correct_batch.html) for customization. Moreover, if you want to use some other cell attribute(s) as the batch key, consider using `scc.set_group_attribute` method ([see details](https://sccloudpy.readthedocs.io/en/latest/api/sccloud.set_group_attribute.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat Previous Steps on the Corrected Data\n",
    "\n",
    "As the count matrix is changed by batch correction, we need to redo steps starting from PCA down to clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.pca(adata)\n",
    "scc.neighbors(adata)\n",
    "scc.louvain(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the composition plot now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.composition_plot(adata, by = 'louvain_labels', condition = 'Channel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything goes properly, you should be able to see that no cluster has a dominant donor cells. Also notice that Louvain algorithm on the corrected data finds 16 clusters, instead of the original 19 ones.\n",
    "\n",
    "Also, FIt-SNE plot is different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.fitsne(adata)\n",
    "scc.embedding(adata, basis = 'fitsne', keys = ['louvain_labels', 'Channel'],\n",
    "              size=1, alpha=0.8, color=bokeh.palettes.all_palettes['Category20'][20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, if everything goes properly, you should be able to see that cells from different donors are better mixed in the right-hand-side plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tSNE Plot\n",
    "\n",
    "In previous sections, we have seen data visualization using FIt-SNE. FIt-SNE is a fast implementation on tSNE algorithm. Including FIt-SNE, `scCloudPy` provides 3 different tSNE plotting methods:\n",
    "\n",
    "* `scc.fitsne`: FIt-SNE plot, using [fitsne](https://github.com/KlugerLab/FIt-SNE) package. [See details](https://sccloudpy.readthedocs.io/en/latest/api/sccloud.fitsne.html)\n",
    "* `scc.tsne`: tSNE plot, using [Multicore-TSNE](https://github.com/DmitryUlyanov/Multicore-TSNE) package. [See details](https://sccloudpy.readthedocs.io/en/latest/api/sccloud.tsne.html)\n",
    "* `scc.net_tsne`: approximated tSNE plot with speed up using Deep Neural Networks (DNN) models. [See details](https://sccloudpy.readthedocs.io/en/latest/api/sccloud.net_tsne.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP Plot\n",
    "\n",
    "Besides tSNE, `scCloudPy` also provides UMAP plotting methods:\n",
    "\n",
    "* `scc.umap`: UMAP plot, using [umap-learn](https://github.com/lmcinnes/umap) package. [See details](https://sccloudpy.readthedocs.io/en/latest/api/sccloud.umap.html)\n",
    "* `scc.net_umap`: Approximated UMAP plot with DNN model based speed up. [See details](https://sccloudpy.readthedocs.io/en/latest/api/sccloud.net_umap.html)\n",
    "\n",
    "Below is the UMAP plot of the data using `umap` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.umap(adata)\n",
    "scc.embedding(adata, basis = 'umap', keys = ['louvain_labels', 'Channel'], \n",
    "              size = 1, alpha = 0.8, color = bokeh.palettes.all_palettes['Category20'][20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential Expression Analysis\n",
    "\n",
    "With the clusters ready, we can now perform Differential Expression (DE) Analysis, which is crucial for identifying the cell type of each cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use `de_analysis` method to run DE analysis. We use Louvain result here. \n",
    "\n",
    "Notice that for notebooks running on Terra, you need to explicitly set `temp_folder` parameter to avoid the incorrect \"No space left\" error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.de_analysis(adata, cluster = 'louvain_labels', auc = False, t = True, fisher = False, mwu = False,\n",
    "                temp_folder = \"/tmp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, DE analysis runs \n",
    "* `auc`: Area under ROC (AUROC) and Area under Precision-Recall (AUPR).\n",
    "* `t`: Welch’s t test.\n",
    "\n",
    "Alternatively, you can also run the follow tests by setting their corresponding parameters to be `True`:\n",
    "* `fisher`: Fisher’s exact test.\n",
    "* `mwu`: Mann-Whitney U test.\n",
    "\n",
    "DE analysis result is stored with key `de_res` (by default) in `varm` field of data. See [documentation](https://sccloudpy.readthedocs.io/en/latest/api/sccloud.de_analysis.html) for more details. \n",
    "\n",
    "To load the result in a human-readable format, use `markers` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_dict = scc.markers(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `markers`:\n",
    "* Sort genes by WAD scores in descending order;\n",
    "* Use $\\alpha = 0.05$ significance level on q-values for inference.\n",
    "\n",
    "See [documentation](https://sccloudpy.readthedocs.io/en/latest/api/sccloud.markers.html) for customizing these parameters.\n",
    "\n",
    "Let's see the up-regulated genes for Cluster 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_dict['1']['up']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among them, **TRAC** worth notification. It is a critical marker for T cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use Volcano plot to see the DE result. Below is such a plot w.r.t. Cluster 1 with log fold change being the metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.volcano(adata, cluster_ids = ['1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To store a specific DE analysis result to file, you can `write_results_to_excel` methods in `scCloud`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scc.write_results_to_excel(marker_dict, \"MantonBM_nonmix_subset.louvain_labels.de.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell Type Annotation\n",
    "\n",
    "After done with DE analysis, we can use the test result to annotate the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype_dict = scc.infer_cell_types(adata, markers = 'human_immune', de_test = 't')\n",
    "cluster_names = scc.infer_cluster_names(celltype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`infer_cell_types` has 2 critical parameters to set:\n",
    "* `markers`: Either `'human_immune'`, `'mouse_immune'`, `'human_brain'`, `'mouse_brain'`, or a user-specified marker dictionary.\n",
    "* `de_test`: Decide which DE analysis test to be used for cell type inference. It can be either `'t'`, `'fisher'`, or `'mwu'`.\n",
    "\n",
    "`infer_cluster_names` by default uses `threshold = 0.5` to filter out candidate cell types of scores lower than 0.5.\n",
    "\n",
    "See [documentation](https://sccloudpy.readthedocs.io/en/latest/api/sccloud.infer_cell_types.html) for details.\n",
    "\n",
    "Next, substitute the inferred cluster names in data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.rename_categories('louvain_labels', cluster_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot data with cluster names. You can either plot names on data or not, by setting `labels_on_data` flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.embedding(adata, basis = 'fitsne', keys = ['louvain_labels'], labels_on_data = False,\n",
    "              padding = (0.1, 0.01), width = 600, size = 1, alpha = 0.8,\n",
    "              color = bokeh.palettes.all_palettes['Category20'][20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.embedding(adata, basis = 'fitsne', keys = ['louvain_labels'], labels_on_data = True,\n",
    "              padding = (0.1, 0.01), width = 600, size = 1, alpha = 0.8,\n",
    "              color = bokeh.palettes.all_palettes['Category20'][20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene-specific Plots\n",
    "\n",
    "### Dot Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_genes = ['CD38', 'JCHAIN', 'FCGR3A', 'HLA-DPA1', 'CD14', 'CD79A', 'MS4A1', 'CD34', 'TRAC', 'CD3D', 'CD8A',\n",
    "                'CD8B', 'GYPA', 'NKG7', 'CD4', 'SELL', 'CCR7']\n",
    "\n",
    "scc.dotplot(adata, keys = marker_genes, by = 'louvain_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.heatmap(adata, keys = marker_genes, by = 'louvain_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violin Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.violin(adata, keys = ['TRAC'], by = 'louvain_labels', width = 900, height = 450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.embedding(adata, basis = 'fitsne', keys = ['TRAC', 'CD79A', 'CD14', 'CD34'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell Development Trajectory and Diffusion Map\n",
    "\n",
    "Alternative, `scCloudPy` provides cell development trajectory plots using Force-directed Layout (FLE) algorithm:\n",
    "* `scc.fle`: FLE plot, using Force-Atlas 2 algorithm in [forceatlas2-python](https://github.com/klarman-cell-observatory/forceatlas2-python) package. [See details](https://sccloudpy.readthedocs.io/en/latest/api/sccloud.fle.html)\n",
    "* `scc.net_fle`: Approximated FLE plot with DNN model based speed up. [See details](https://sccloudpy.readthedocs.io/en/latest/api/sccloud.net_fle.html)\n",
    "\n",
    "Moreover, calculation of FLE plots is on Diffusion Map of the data, rather than directly on data points, in order to achieve a better efficiency. Thus, we need to first compute the diffusion map structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.diffmap(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `diffmap` method uses:\n",
    "* Number of Diffusion Components = $100$.\n",
    "* Compute diffusion map from PCA matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm['X_diffmap'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to calculate the cell developing trajectory. Below is FLE plot using `net_fle` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.net_fle(adata)\n",
    "scc.embedding(adata, basis = 'net_fle', keys = ['louvain_labels'],\n",
    "              size = 1, alpha = 0.8, color = bokeh.palettes.all_palettes['Category20'][20],\n",
    "              width = 700, height = 700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Advanced) More on Clustering\n",
    "\n",
    "In previous sections, we use Louvain algorithm for clustering. Including Louvain, `scCloudPy` provides 4 algorithms:\n",
    "* `scc.louvain`: Louvain algorithm, using [louvain-igraph](https://github.com/vtraag/louvain-igraph) package.\n",
    "* `scc.leiden`: Leiden algorithm, using [leidenalg](https://github.com/vtraag/leidenalg) package.\n",
    "* `scc.spectral_louvain`: Spectral Louvain algorithm, which requires Diffusion Map.\n",
    "* `scc.spectral_leiden`: Spectral Leiden algorithm, which requires Diffusion Map.\n",
    "\n",
    "We have used `louvain` method. Its documentation is [here](https://sccloudpy.readthedocs.io/en/latest/api/sccloud.louvain.html). By default, it uses resolution 1.3, does clustering via PCA matrix, and stores result with key `louvain_labels` in `obs` field of data.\n",
    "\n",
    "**Leiden Algorithm.** `leiden` method ([See details](https://sccloudpy.readthedocs.io/en/latest/api/sccloud.leiden.html)), by default, uses resolution 1.3, does clustering via PCA matrix, runs the algorithm until reaching its optimal clustering (`n_iter` parameter), and stores result with key `leiden_labels` in `obs` field of data.\n",
    "\n",
    "However, with the default `n_iter` parameter, it can take a very long time to converge, while the result doesn't improved much. So instead, you may think of feed it a small positive number to put a hard specification on how many iterations to run. Here, we use 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.leiden(adata, n_iter = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare its result with Louvain's via UMAP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.embedding(adata, basis = 'umap', keys = ['louvain_labels', 'leiden_labels'],\n",
    "              size = 1, alpha = 0.8, color = bokeh.palettes.all_palettes['Category20'][20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spectral Louvain Algorithm** `spectral_louvain` method ([See details](https://sccloudpy.readthedocs.io/en/latest/api/sccloud.spectral_louvain.html)), by default, uses resolution 1.3, runs KMeans on Diffusion Map, does clustering on PCA matrix, and stores result with key `spectral_louvain_labels` in `obs` field of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.spectral_louvain(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spectral Leiden Algorithm** `spectral_leiden` method ([See details](https://sccloudpy.readthedocs.io/en/latest/api/sccloud.spectral_leiden.html)), by default, uses resolution 1.3, runs KMeans on Diffusion Map, does clustering on PCA matrix, and stores result with key `spectral_leiden_labels` in `obs` field of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.spectral_leiden(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the UMAP plots of the clustering results of these two algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc.embedding(adata, basis = 'umap', keys = ['spectral_louvain_labels', 'spectral_leiden_labels'],\n",
    "              size = 1, alpha = 0.8, color = bokeh.palettes.all_palettes['Category20'][20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
